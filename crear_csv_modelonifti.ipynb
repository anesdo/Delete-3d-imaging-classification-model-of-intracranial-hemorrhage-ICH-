{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''%pip install tensorflow==2.2.0\n",
    "%pip install tensorflow-gpu==2.2.0 '''\n",
    "#%pip install dicom2nifti\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import dicom2nifti\n",
    "import dicom2nifti.settings as settings\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "import cv2\n",
    "import nibabel as nib    #para leer los nifti\n",
    "from scipy import ndimage   #Multidimensional image processing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "############################################# \n",
    "#.........DEFINICIÓN DE LOS CSV..............\n",
    "#############################################\n",
    "def crear_csv(train_list, label_list, name_csv, data=[]):\n",
    "    if name_csv is not 'TRAIN':\n",
    "        train_list=np.transpose(train_list)\n",
    "        label_list=np.transpose(label_list)\n",
    "\n",
    "        data = {'name': train_list,\n",
    "                'label': label_list}\n",
    "\n",
    "    df = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "    df.to_csv('/srv/data/HIC/datos/csv/NIFTI_'+name_csv+'.csv') \n",
    "    \n",
    "############################################# \n",
    "#...............PREPROCESADO.................\n",
    "#############################################\n",
    "\n",
    "def read_nifti_file(filepath):   #Aquí solo define la función. \n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    #print(filepath)\n",
    "    scan = nib.load(filepath)   #nib es una clase \n",
    "    #print(scan.dataobj.slope, scan.dataobj.inter)\n",
    "    #print(scan.shape)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    #sample_stack(scan, rows=4, cols=4, start_with=0, show_every=1)   \n",
    "    n,m,l=scan.shape\n",
    "    img_data=np.zeros([128,128,l])\n",
    "    for i in range(0,l):\n",
    "        img_data[:,:,i]=cv2.resize(scan[:,:,i],(128,128))\n",
    "    #hist(img_data)\n",
    "     \n",
    "    #print(scan[0,0,0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return img_data\n",
    "\n",
    "\n",
    "\n",
    "def normalize(image):\n",
    "    MIN_BOUND=15\n",
    "    MAX_BOUND=100\n",
    "    \n",
    "    image = (image - MIN_BOUND) / (MAX_BOUND - MIN_BOUND)\n",
    "    \n",
    "    image[image>1] = 0. #quitar información\n",
    "    image[image<0] = 0.\n",
    "    image = ndimage.rotate(image, 90, reshape=False)\n",
    "    return image\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 45\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "def resize_volume_black(img):  \n",
    "    n,m,l=img.shape\n",
    "    #print('img',img.shape)\n",
    "    img_data=np.zeros([l,128,128])\n",
    "    for i in range(0,l):\n",
    "        img_data[i,:,:]=cv2.resize(img[:,:,i],(128,128))\n",
    "    img_p=list(img_data)\n",
    "    \n",
    "    \n",
    "    n,m,l=img_data.shape\n",
    "    matriz_float = np.zeros((m,l))\n",
    "    #print('matriz_float',matriz_float.shape)\n",
    "    \n",
    "    matriz_float = np.float32(matriz_float)\n",
    "    for ind in range(n,45):\n",
    "        img_p.append(matriz_float)\n",
    "    img_p=np.array(img_p)\n",
    "    #print('img_nuevo',img_p.shape)\n",
    "    #sample_stack(img_p, rows=6, cols=6, start_with=0, show_every=1)\n",
    "    \n",
    "    n,m,l=img_p.shape\n",
    "    img_data=np.zeros([128,128,n])\n",
    "    \n",
    "    for i in range(0,n):\n",
    "        img_data[:,:,i]=img_p[i,:,:]\n",
    "    \n",
    "    return img_data\n",
    "\n",
    "#COMPENDIO DE LAS FUNCIONES DEFINIDAS ARRIBA:\n",
    "def process_scan(path,direc):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    #print(path)\n",
    "    #name_image=os.listdir(path)\n",
    "    #path_image= os.path.join(path, name_image[0])\n",
    "    #print(path[-3:-1])\n",
    "   \n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)    #no importan tanto el nombre (path o filepath) sino el ORDEN!!!\n",
    "    \n",
    "    #hist(volume)\n",
    "    #sample_stack(volume, rows=4, cols=4, start_with=0, show_every=1)\n",
    "    \n",
    "    # Normalize\n",
    "    volume = normalize(volume)      #da igual que ponga volume o pepito, lo importante es que sea la IMAGEN!\n",
    "    #hist(volume)\n",
    "    #sample_stack(volume, rows=4, cols=4, start_with=0, show_every=1)\n",
    "    \n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume_black(volume)\n",
    "    #hist(volume)\n",
    "    #sample_stack(volume, rows=6, cols=6, start_with=0, show_every=1)\n",
    "    np.save('/srv/data/HIC/datos/NIFTI_PREPROCESADO/'+str(direc)+'.npy',volume)   #./ = la dirección desde donde tengo yo este archivo si está en la misma carpeta que el notebook. si dicomtonifti está dentro de la carpeta code\n",
    "    return volume\n",
    "\n",
    "# VISUALIZAR CORTES\n",
    "def sample_stack(stack, rows=5, cols=5, start_with=0, show_every=1):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[:,:,ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "# VISUALIZAR CORTES\n",
    "def hist(stack):\n",
    "    fig= plt.hist(stack.flatten(), bins=80)\n",
    "    plt.xlabel(\"Hounsfield Units (HU)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"############################################# \\n#...............DICOM TO NIFTI...............\\n#############################################\\n#HIC\\nprint('[INFO] CAMBIO DE FORMATO HIC DICOM TO NIFTI')\\nfor dirpath, dirnames, fileList in os.walk('/srv/data/HIC/datos/HIC/DATASETS_HIC/'):\\n    for subfolder in dirnames:\\n        print(subfolder)\\n        dicom_directory='/srv/data/HIC/datos/HIC/DATASETS_HIC/'+subfolder\\n        output_folder='/srv/data/HIC/datos/NIFTI/HIC/'+subfolder\\n        if not os.path.exists(output_folder):\\n            os.makedirs(output_folder)\\n        settings.disable_validate_orthogonal() #importante que esté\\n        settings.disable_validate_slice_increment() #importante que esté\\n        settings.disable_validate_orientation() #importante que esté\\n        dicom2nifti.convert_directory(dicom_directory, output_folder)\\n\\n\\n# Controles\\nimport pandas as pd\\nprint('[INFO] CAMBIO DE FORMATO CONTROLES DICOM TO NIFTI')\\nfor dirpath, dirnames, fileList in os.walk('/srv/data/HIC/datos/CONTROL/DICOM_NORMALES/CONTROLES_DICOM_CODIFICADOS/FILESET/'):\\n    for subfolder in dirnames:\\n        print(subfolder)\\n        dicom_directory='/srv/data/HIC/datos/CONTROL/DICOM_NORMALES/CONTROLES_DICOM_CODIFICADOS/FILESET/'+subfolder+'/0/0/'\\n        output_folder='/srv/data/HIC/datos/NIFTI/CONTROL/'+subfolder\\n        if not os.path.exists(output_folder):\\n            os.makedirs(output_folder)\\n        settings.disable_validate_orthogonal() #importante que esté\\n        settings.disable_validate_slice_increment() #importante que esté\\n        settings.disable_validate_orientation()\\n        dicom2nifti.convert_directory(dicom_directory, output_folder)\\nprint('[INFO] FIN DEL CAMBIO DE FORMATO CONTROLES DICOM TO NIFTI')\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''############################################# \n",
    "#...............DICOM TO NIFTI...............\n",
    "#############################################\n",
    "#HIC\n",
    "print('[INFO] CAMBIO DE FORMATO HIC DICOM TO NIFTI')\n",
    "for dirpath, dirnames, fileList in os.walk('/srv/data/HIC/datos/HIC/DATASETS_HIC/'):\n",
    "    for subfolder in dirnames:\n",
    "        print(subfolder)\n",
    "        dicom_directory='/srv/data/HIC/datos/HIC/DATASETS_HIC/'+subfolder\n",
    "        output_folder='/srv/data/HIC/datos/NIFTI/HIC/'+subfolder\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        settings.disable_validate_orthogonal() #importante que esté\n",
    "        settings.disable_validate_slice_increment() #importante que esté\n",
    "        settings.disable_validate_orientation() #importante que esté\n",
    "        dicom2nifti.convert_directory(dicom_directory, output_folder)\n",
    "\n",
    "\n",
    "# Controles\n",
    "import pandas as pd\n",
    "print('[INFO] CAMBIO DE FORMATO CONTROLES DICOM TO NIFTI')\n",
    "for dirpath, dirnames, fileList in os.walk('/srv/data/HIC/datos/CONTROL/DICOM_NORMALES/CONTROLES_DICOM_CODIFICADOS/FILESET/'):\n",
    "    for subfolder in dirnames:\n",
    "        print(subfolder)\n",
    "        dicom_directory='/srv/data/HIC/datos/CONTROL/DICOM_NORMALES/CONTROLES_DICOM_CODIFICADOS/FILESET/'+subfolder+'/0/0/'\n",
    "        output_folder='/srv/data/HIC/datos/NIFTI/CONTROL/'+subfolder\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "        settings.disable_validate_orthogonal() #importante que esté\n",
    "        settings.disable_validate_slice_increment() #importante que esté\n",
    "        settings.disable_validate_orientation()\n",
    "        dicom2nifti.convert_directory(dicom_directory, output_folder)\n",
    "print('[INFO] FIN DEL CAMBIO DE FORMATO CONTROLES DICOM TO NIFTI')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = 5  \n",
    "test_split=0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT scans with normal brain tissue: 96\n",
      "CT scans with abnormal brain tissue: 118\n",
      "99\n",
      "93\n",
      "61\n",
      "259\n",
      "230\n",
      "149\n",
      "117\n",
      "135\n",
      "235\n",
      "21\n",
      "98\n",
      "96\n",
      "90\n",
      "282\n",
      "7\n",
      "286\n",
      "288\n",
      "34\n",
      "37\n",
      "141\n",
      "87\n",
      "15\n",
      "256\n",
      "268\n",
      "285\n",
      "42\n",
      "250\n",
      "124\n",
      "237\n",
      "266\n",
      "51\n",
      "86\n",
      "127\n",
      "119\n",
      "125\n",
      "292\n",
      "131\n",
      "132\n",
      "147\n",
      "232\n",
      "53\n",
      "108\n",
      "290\n",
      "283\n",
      "271\n",
      "75\n",
      "82\n",
      "13\n",
      "240\n",
      "95\n",
      "281\n",
      "28\n",
      "12\n",
      "63\n",
      "246\n",
      "88\n",
      "74\n",
      "69\n",
      "54\n",
      "35\n",
      "274\n",
      "261\n",
      "148\n",
      "122\n",
      "234\n",
      "10\n",
      "30\n",
      "39\n",
      "29\n",
      "239\n",
      "77\n",
      "264\n",
      "14\n",
      "26\n",
      "249\n",
      "62\n",
      "106\n",
      "118\n",
      "144\n",
      "120\n",
      "102\n",
      "50\n",
      "110\n",
      "128\n",
      "8\n",
      "126\n",
      "27\n",
      "284\n",
      "257\n",
      "277\n",
      "36\n",
      "243\n",
      "100\n",
      "244\n",
      "115\n",
      "245\n",
      "236\n",
      "20\n",
      "66\n",
      "92\n",
      "121\n",
      "3\n",
      "79\n",
      "24\n",
      "17\n",
      "272\n",
      "146\n",
      "68\n",
      "242\n",
      "112\n",
      "104\n",
      "238\n",
      "91\n",
      "296\n",
      "78\n",
      "269\n",
      "70\n",
      "97\n",
      "140\n",
      "31\n",
      "116\n",
      "99\n",
      "32\n",
      "23\n",
      "149\n",
      "117\n",
      "123\n",
      "135\n",
      "150\n",
      "21\n",
      "98\n",
      "7\n",
      "33\n",
      "0\n",
      "101\n",
      "103\n",
      "105\n",
      "37\n",
      "141\n",
      "15\n",
      "107\n",
      "114\n",
      "42\n",
      "124\n",
      "44\n",
      "4\n",
      "47\n",
      "127\n",
      "134\n",
      "11\n",
      "113\n",
      "119\n",
      "125\n",
      "45\n",
      "131\n",
      "132\n",
      "147\n",
      "138\n",
      "16\n",
      "108\n",
      "41\n",
      "46\n",
      "13\n",
      "143\n",
      "9\n",
      "5\n",
      "129\n",
      "28\n",
      "12\n",
      "43\n",
      "6\n",
      "148\n",
      "122\n",
      "10\n",
      "18\n",
      "30\n",
      "145\n",
      "1\n",
      "19\n",
      "39\n",
      "2\n",
      "29\n",
      "142\n",
      "14\n",
      "26\n",
      "106\n",
      "118\n",
      "139\n",
      "144\n",
      "120\n",
      "102\n",
      "50\n",
      "48\n",
      "110\n",
      "130\n",
      "128\n",
      "8\n",
      "109\n",
      "136\n",
      "126\n",
      "27\n",
      "36\n",
      "49\n",
      "100\n",
      "115\n",
      "20\n",
      "40\n",
      "121\n",
      "3\n",
      "24\n",
      "17\n",
      "146\n",
      "112\n",
      "137\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "############################################# \n",
    "#............CONOCER QUÉ TENEMOS.............\n",
    "#############################################\n",
    "\n",
    "# Folder \"CONTROL\" consist of CT scans having normal brain tissue.\n",
    "normal_scan_paths = [\n",
    "    os.path.join(\"/srv/data/HIC/datos/NIFTI/CONTROL/\", x)      #está juntando la ruta donde está el colab con Mosmed... con x \n",
    "    for x in os.listdir(\"/srv/data/HIC/datos/NIFTI/CONTROL/\")     #os.listdir () --> te hace una lista de lo que hay dentro de la carpeta que pongas ()\n",
    "]\n",
    "\n",
    "# Folder \"CONTROL\" consist of CT scans having abnormal brain tissue.\n",
    "abnormal_scan_paths = [\n",
    "    os.path.join(\"/srv/data/HIC/datos/NIFTI/HIC/\", x)\n",
    "    for x in os.listdir(\"/srv/data/HIC/datos/NIFTI/HIC/\")\n",
    "]\n",
    "\n",
    "print(\"CT scans with normal brain tissue: \" + str(len(normal_scan_paths)))\n",
    "print(\"CT scans with abnormal brain tissue: \" + str(len(abnormal_scan_paths)))\n",
    "\n",
    "\n",
    "############################################# \n",
    "#..........CREAMOS LOS CSV...................\n",
    "#############################################\n",
    "   \n",
    "#CREAMOS EL EXCEL CON LOS PATHS Y LAS ETIQUETAS: \n",
    "tipo=['HIC','CONTROL']\n",
    "for itipo in tipo:\n",
    "    train_list=[]\n",
    "    label_list = []\n",
    "    for dirpath, dirnames, fileList in os.walk('/srv/data/HIC/datos/NIFTI/'+str(itipo)+'/'):\n",
    "        for direc in dirnames:\n",
    "            print(direc)\n",
    "            for dirpath1, dirnames1, fileList1 in os.walk('/srv/data/HIC/datos/NIFTI/'+str(itipo)+'/'+str(direc)+'/'):\n",
    "                file=fileList1[0]\n",
    "                process_scan(dirpath1+file,direc)\n",
    "            \n",
    "        \n",
    "            train_list.append('/srv/data/HIC/datos/NIFTI_PREPROCESADO/'+str(direc)+'.npy')\n",
    "            if str(itipo) is 'HIC':\n",
    "                label_list.append(1) \n",
    "            else:\n",
    "                label_list.append(0) \n",
    "    \n",
    "    if str(itipo) is 'CONTROL':\n",
    "        train_list_CONTROL=train_list\n",
    "        label_list_CONTROL=label_list\n",
    "        crear_csv(train_list_CONTROL, label_list_CONTROL, 'TRAIN_CONTROL')\n",
    "    else:\n",
    "        train_list_HIC=train_list\n",
    "        label_list_HIC=label_list \n",
    "        crear_csv(train_list_HIC, label_list_HIC, 'TRAIN_HIC')\n",
    "\n",
    "train_list_CONTROL=np.transpose(train_list_CONTROL)\n",
    "label_list_CONTROL=np.transpose(label_list_CONTROL)\n",
    "train_list_HIC=np.transpose(train_list_HIC)\n",
    "label_list_HIC=np.transpose(label_list_HIC)\n",
    "\n",
    "names=np.concatenate((train_list_CONTROL, train_list_HIC))\n",
    "labels=np.concatenate((label_list_CONTROL, label_list_HIC))\n",
    "\n",
    "#TRAIN\n",
    "data = {'name': names,'label': labels}\n",
    "crear_csv(names, labels, '_', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TRAIN CSV  (160, 3)\n",
      "[INFO] TEST CSV  (54, 3)\n",
      "KFold, shuffle=False (default)\n",
      "TRAIN 1 (128, 2)\n",
      "VAL 1 (32, 2)\n",
      "\n",
      "\n",
      "TRAIN 2 (128, 2)\n",
      "VAL 2 (32, 2)\n",
      "\n",
      "\n",
      "TRAIN 3 (128, 2)\n",
      "VAL 3 (32, 2)\n",
      "\n",
      "\n",
      "TRAIN 4 (128, 2)\n",
      "VAL 4 (32, 2)\n",
      "\n",
      "\n",
      "TRAIN 5 (128, 2)\n",
      "VAL 5 (32, 2)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################################# \n",
    "#.............CREAR KFOLDS...................\n",
    "#############################################\n",
    "\n",
    "# Read data\n",
    "# Assuming it has two cols:\n",
    "# name: path to each image with its extension\n",
    "# label: labels (here it is 0s and 1s) -> binary classification\n",
    "df = pd.read_csv('/srv/data/HIC/datos/csv/NIFTI__.csv')\n",
    "df = df.iloc[np.random.permutation(len(df))]\n",
    "df = df.astype(str)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.25)\n",
    "\n",
    "print('[INFO] TRAIN CSV ',train_df.shape)\n",
    "print('[INFO] TEST CSV ',test_df.shape)\n",
    "train_df.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN.csv')\n",
    "test_df.to_csv('/srv/data/HIC/datos/csv/NIFTI_TEST.csv')\n",
    "\n",
    "Xtrain = train_df['name']\n",
    "ytrain = train_df['label']\n",
    "\n",
    "print(\"KFold, shuffle=False (default)\")\n",
    "kf = KFold(n_splits=SPLIT, random_state=True, shuffle=True)\n",
    "\n",
    "X_train=[]\n",
    "X_val=[]\n",
    "y_train=[]\n",
    "y_val=[]\n",
    "i=1\n",
    "for train_index, test_index in kf.split(Xtrain, ytrain):\n",
    "    train_index=list(train_index)\n",
    "    test_index=list(test_index)\n",
    "\n",
    "    Xtrain = np.array(Xtrain)\n",
    "    ytrain = np.array(ytrain)\n",
    "    if(i is 1):\n",
    "        X_train1 , X_val1 = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train1, y_val1 = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        data = {'name': X_train1,\n",
    "        'label': y_train1}\n",
    "        dftrain1 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dftrain1.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN'+str(i)+'.csv')\n",
    "        \n",
    "        data = {'name': X_val1,\n",
    "        'label': y_val1}\n",
    "        dfval1 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dfval1.to_csv('/srv/data/HIC/datos/csv/NIFTI_VAL'+str(i)+'.csv')\n",
    "        \n",
    "        i=i+1\n",
    "    elif(i is 2):\n",
    "        X_train2 , X_val2 = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train2, y_val2 = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        data = {'name': X_train2,\n",
    "        'label': y_train2}\n",
    "        dftrain2 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dftrain2.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN'+str(i)+'.csv')\n",
    "        \n",
    "        data = {'name': X_val2,\n",
    "        'label': y_val2}\n",
    "        dfval2 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dfval2.to_csv('/srv/data/HIC/datos/csv/NIFTI_VAL'+str(i)+'.csv')\n",
    "        \n",
    "        i=i+1\n",
    "    elif(i is 3):\n",
    "        X_train3 , X_val3 = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train3, y_val3 = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        data = {'name': X_train3,\n",
    "        'label': y_train3}\n",
    "        dftrain3 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dftrain3.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN'+str(i)+'.csv')\n",
    "        \n",
    "        data = {'name': X_val3,\n",
    "        'label': y_val3}\n",
    "        dfval3 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dfval3.to_csv('/srv/data/HIC/datos/csv/NIFTI_VAL'+str(i)+'.csv')\n",
    "        \n",
    "        i=i+1\n",
    "    elif(i is 4):\n",
    "        X_train4 , X_val4 = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train4, y_val4 = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        data = {'name': X_train4,\n",
    "        'label': y_train4}\n",
    "        dftrain4 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dftrain4.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN'+str(i)+'.csv')\n",
    "        \n",
    "        data = {'name': X_val4,\n",
    "        'label': y_val4}\n",
    "        dfval4 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dfval4.to_csv('/srv/data/HIC/datos/csv/NIFTI_VAL'+str(i)+'.csv')\n",
    "        \n",
    "        i=i+1\n",
    "    elif(i is 5):\n",
    "        X_train5 , X_val5 = Xtrain[train_index], Xtrain[test_index]\n",
    "        y_train5, y_val5 = ytrain[train_index], ytrain[test_index]\n",
    "        \n",
    "        data = {'name': X_train5,\n",
    "        'label': y_train5}\n",
    "        dftrain5 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dftrain5.to_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN'+str(i)+'.csv')\n",
    "        \n",
    "        data = {'name': X_val5,\n",
    "        'label': y_val5}\n",
    "        dfval5 = pd.DataFrame(data, columns = ['name', 'label']) \n",
    "        dfval5.to_csv('/srv/data/HIC/datos/csv/NIFTI_VAL'+str(i)+'.csv')      \n",
    "        i=i+1\n",
    "        \n",
    "#REVISAR KFOLDS HECHOS Y TAMAÑO   \n",
    "print('TRAIN 1',dftrain1.shape)\n",
    "print('VAL 1', dfval1.shape)\n",
    "print('\\n')\n",
    "\n",
    "print('TRAIN 2',dftrain2.shape)\n",
    "print('VAL 2',dfval2.shape)\n",
    "print('\\n')\n",
    "\n",
    "print('TRAIN 3',dftrain3.shape)\n",
    "print('VAL 3',dfval3.shape)\n",
    "print('\\n')\n",
    "\n",
    "print('TRAIN 4',dftrain4.shape)\n",
    "print('VAL 4',dfval4.shape)\n",
    "print('\\n')\n",
    "\n",
    "print('TRAIN 5',dftrain5.shape)\n",
    "print('VAL 5',dfval5.shape)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] LEYENDO CSV \n",
      "\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/40/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/24/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/99/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/131/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/121/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/29/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/82/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/10/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/115/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/15/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/10/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/124/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/268/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/257/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/109/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/42/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/62/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/269/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/32/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/264/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/148/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/148/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/88/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/30/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/145/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/0/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/125/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/47/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/277/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/36/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/124/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/141/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/127/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/149/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/101/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/121/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/126/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/105/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/14/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/118/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/16/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/135/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/49/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/78/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/138/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/104/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/282/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/244/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/99/\n",
      "/srv/data/HIC/datos/NIFTI/CONTROL/110/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/144/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/54/\n",
      "/srv/data/HIC/datos/NIFTI/HIC/93/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/srv/data/HIC/datos/NIFTI/HIC/93/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-111de60a7c15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCSV_TRAIN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mprocess_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#es un array 4D (100 (nº de TC) x 128 x 128 x 64)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/srv/data/HIC/datos/NIFTI_PREPROCESADO/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-35323ae70541>\u001b[0m in \u001b[0;36mprocess_scan\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m\"\"\"Read and resize volume\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;31m#print(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mname_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mpath_image\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m#print(path[-3:-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/srv/data/HIC/datos/NIFTI/HIC/93/'"
     ]
    }
   ],
   "source": [
    "x_train=[]\n",
    "y_train=[]\n",
    "x_val=[]\n",
    "y_val=[]\n",
    "CSV_TRAIN=[]\n",
    "CSV_VAL=[]\n",
    "    \n",
    "print('[INFO] LEYENDO CSV \\n')\n",
    "\n",
    "CSV_TRAIN = pd.read_csv('/srv/data/HIC/datos/csv/NIFTI_TRAIN.csv',sep=',')\n",
    "CSV_VAL = pd.read_csv('/srv/data/HIC/datos/csv/NIFTI_TEST.csv',sep=',')\n",
    "train_list=[]\n",
    "label_list=[]\n",
    "for path in CSV_TRAIN['name']:\n",
    "    print(path)\n",
    "    process_scan(path) #es un array 4D (100 (nº de TC) x 128 x 128 x 64)\n",
    "    train_list.append('/srv/data/HIC/datos/NIFTI_PREPROCESADO/'+str(path[-3:-1])+'.npy')\n",
    "\n",
    "print(train_list_HIC, CSV_TRAIN['name'])\n",
    "\n",
    "#Crear CSV train\n",
    "data = {'name': train_list,'label': CSV_VAL['label']}\n",
    "crear_csv(names, labels, 'TRAIN', data)\n",
    "\n",
    "\n",
    "train_list=[]\n",
    "label_list=[]\n",
    "for path in CSV_VAL['name']:\n",
    "    print(path)\n",
    "    process_scan(path) #es un array 4D (100 (nº de TC) x 128 x 128 x 64)\n",
    "    train_list.append('/srv/data/HIC/datos/NIFTI_PREPROCESADO/'+str(path[-3:-1])+'.npy')\n",
    "\n",
    "print(train_list_HIC, CSV_VAL['name'])\n",
    "  \n",
    "\n",
    "#Crear CSV train\n",
    "#TRAIN\n",
    "data = {'name': train_list,'label': CSV_VAL['label']}\n",
    "crear_csv(names, labels, 'TRAIN', data)\n",
    "\n",
    "\n",
    "x_val = [process_scan(path) for path in CSV_VAL['name']]\n",
    "y_val=CSV_VAL['label']\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_val = np.asarray(x_val)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "print(\"Number of samples in train and validation are %d and %d.\" % (x_train.shape[0], x_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip='HIC'\n",
    "paciente=93\n",
    "import nibabel as nib\n",
    "import os\n",
    "# VISUALIZAR CORTES\n",
    "def sample_stack(stack, rows=5, cols=5, start_with=0, show_every=1):\n",
    "    fig,ax = plt.subplots(rows,cols,figsize=[12,12])\n",
    "    for i in range(rows*cols):\n",
    "        ind = start_with + i*show_every\n",
    "        ax[int(i/rows),int(i % rows)].set_title('slice %d' % ind)\n",
    "        ax[int(i/rows),int(i % rows)].imshow(stack[:,:,ind],cmap='gray')\n",
    "        ax[int(i/rows),int(i % rows)].axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "j= os.listdir('/srv/data/HIC/datos/NIFTI/'+tip+'/'+str(paciente))\n",
    "print(j)\n",
    "img = nib.load('/srv/data/HIC/datos/NIFTI/'+tip+'/'+str(paciente)+'/'+j[0])\n",
    "image_data = img.get_fdata()#\n",
    "print(image_data.shape)\n",
    "sample_stack(image_data, rows=5, cols=5, start_with=0, show_every=1)\n",
    "'''    \n",
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.imshow(image_data[:,:,27],cmap='gray')'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
